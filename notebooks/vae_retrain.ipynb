{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "049785e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 23\n",
      "Traceback (most recent call last):\n",
      "  File \"../main.py\", line 535, in <module>\n",
      "    model = instantiate_from_config(config.model)\n",
      "  File \"/home/davbauer/work/stable-diffusion/ldm/util.py\", line 85, in instantiate_from_config\n",
      "    return get_obj_from_str(config[\"target\"])(**config.get(\"params\", dict()))\n",
      "  File \"/home/davbauer/work/stable-diffusion/ldm/util.py\", line 93, in get_obj_from_str\n",
      "    return getattr(importlib.import_module(module, package=None), cls)\n",
      "  File \"/home/davbauer/software/miniconda3/envs/ldm/lib/python3.8/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/davbauer/work/stable-diffusion/ldm/models/autoencoder.py\", line 10, in <module>\n",
      "    from ldm.modules.autoencoder_transformations import Identity, Invert\n",
      "  File \"/home/davbauer/work/stable-diffusion/ldm/modules/autoencoder_transformations.py\", line 5, in <module>\n",
      "    class Identity(torch.Module):\n",
      "AttributeError: module 'torch' has no attribute 'Module'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"../main.py\", line 740, in <module>\n",
      "    if trainer.global_rank == 0:\n",
      "NameError: name 'trainer' is not defined\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('python ../main.py --train true --base ../configs/autoencoder/autoencoder_kl_16x16x16.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72f409f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from ldm.models.autoencoder import VQModelRetrainable, AutoencoderKL\n",
    "from ldm.util import instantiate_from_config\n",
    "from ldm.data.lsun import LSUNCatsTrain, LSUNCatsValidation\n",
    "from ldm.data.imagenet import ImageNetTrain, ImageNetValidation\n",
    "\n",
    "from pytorch_lightning.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edcf8ce",
   "metadata": {},
   "source": [
    "### Create model from config and load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1967b1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 8, 16, 16) = 2048 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n",
      "Restored from ../models/first_stage_models/vq-f16/model.ckpt with 0 missing and 0 unexpected keys\n"
     ]
    }
   ],
   "source": [
    "modeldir = '../models/first_stage_models/vq-f16/'\n",
    "config = OmegaConf.load(os.path.join(modeldir, 'config.yaml'))\n",
    "model = instantiate_from_config(config.model)\n",
    "model.init_from_ckpt(os.path.join(modeldir, 'model.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3fc9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQModelRetrainable(model, target_transformation_fn = lambda x: x)\n",
    "model.clear_decoder()\n",
    "model.restore_decoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b07a36a",
   "metadata": {},
   "source": [
    "### Load ImageNet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df60eee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1 files from filelist during filtering.\n"
     ]
    }
   ],
   "source": [
    "data = ImageNetTrain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8c9b7e",
   "metadata": {},
   "source": [
    "### Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6279ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.vqmodel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
